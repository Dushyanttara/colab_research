{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark submit ibm coursera",
      "provenance": [],
      "authorship_tag": "ABX9TyPG9rnrr3P69mEDKRGbYbYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dushyanttara/colab_research/blob/master/spark_submit_ibm_coursera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hdpoUeijvRD",
        "colab_type": "text"
      },
      "source": [
        "## Coursera IBM (submit assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udy1o8wxi5nv",
        "colab_type": "text"
      },
      "source": [
        "First we will load spark and make our environment suitable for using spark. Some key things we need to keep in mind:\n",
        "\n",
        "1. Get correct spark file from apache website\n",
        "2. Get correct jdk setup for your colab environment\n",
        "3. install findspark (automatically detects where spark has been installed in your system)\n",
        "4. setup environment variables\n",
        "5. Configure your spark session\n",
        "6. Run your notebook as it is ( you can even load it directly from the URL provided)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gySaQL4x6f9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFWZ4AUC7IPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6cwLvbu7ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls /usr/lib/jvm/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8pFN5D18Uhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U pyarrow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnsqOZZ9Lod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AiQ8z-I9sRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "import sys,tempfile, urllib\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.executor.memory\",\"4g\")\n",
        "spark.conf.set(\"spark.driver.memory\", \"4g\")\n",
        "spark.conf.set(\"spark.memory.fraction\",\"0.9\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9QqGt7Bkgwe",
        "colab_type": "text"
      },
      "source": [
        "Now you've configured your colab environment to be ready for your spark code, now you can import the code from the assignment notebook, complete your assignment and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFV8SqwqNfep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Please implement a function returning the number of rows in the dataframe\n",
        "def count():\n",
        "    return spark.sql('select ### as cnt from washing').first().cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q75Akv-Nf3sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNumberOfFields():\n",
        "    #TODO Please enter your code here, you are not required to use the template code below\n",
        "    #some reference: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\n",
        "    return len(df.###)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyXadmAIf_XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFieldNames():\n",
        "    #TODO Please enter your code here, you are not required to use the template code below\n",
        "    #some reference: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\n",
        "    return df.###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg_7KD9CgDwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/IBM/coursera/blob/master/coursera_ds/washing.parquet?raw=true\n",
        "!mv washing.parquet?raw=true washing.parquet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI1EJal4gEgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.read.parquet('washing.parquet')\n",
        "df.createOrReplaceTempView('washing')\n",
        "df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV4rZPU1gHLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = None\n",
        "nof = None\n",
        "fn = None\n",
        "\n",
        "cnt = count()\n",
        "print(cnt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rmjf3vigJko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nof = getNumberOfFields()\n",
        "print(nof)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQEwKL8UgL6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fn = getFieldNames()\n",
        "print(fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5TRMENHezE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!rm -f rklib.py\n",
        "!wget https://raw.githubusercontent.com/IBM/coursera/master/rklib.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XRIu0talYDc",
        "colab_type": "text"
      },
      "source": [
        "The submission file is different for each assignment which can be found as the last cell in every assignment notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22GGtLOrfo1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rklib import submit, submitAll\n",
        "import json\n",
        "\n",
        "key = \"SVDiVSHNEeiDqw70MIp2vA\"\n",
        "\n",
        "if type(23) != type(cnt):\n",
        "    raise ValueError('Please make sure that \"cnt\" is a number')\n",
        "    \n",
        "if type(23) != type(nof):\n",
        "    raise ValueError('Please make sure that \"nof\" is a number')\n",
        "\n",
        "if type([]) != type(fn):\n",
        "    raise ValueError('Please make sure that \"fn\" is a list')\n",
        "\n",
        "email = '##email address for coursera##'\n",
        "token = #### your code here ### (have a look here if you need more information on how to obtain the token https://youtu.be/GcDo0Rwe06U?t=276)\n",
        "\n",
        "parts_data = {}\n",
        "parts_data[\"2FjQw\"] = json.dumps(cnt)\n",
        "parts_data[\"j8gMs\"] = json.dumps(nof)\n",
        "parts_data[\"xaauC\"] = json.dumps(fn)\n",
        "\n",
        "\n",
        "submitAll(email, token, key, parts_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4-gIOz9kr0m",
        "colab_type": "text"
      },
      "source": [
        "After you run the previous cell, you should receive the output as **'successful submission'**. \n",
        "Now please go back to your coursera assignment page and check if your submission was correct or not.\n",
        "\n",
        "**Thankyou for using this notebook, If this has been helpful, please consider giving a star to this notebook on github.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmiXBBThlUCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}